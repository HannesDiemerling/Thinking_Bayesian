# Bayesian vs. Frequentist

In this chapter, we contrast the two dominant statistical philosophies using a standard industry problem: A/B Testing.

## The Scenario: Marketing Conversion

You run an e-commerce website. You are testing two versions of a checkout button:
* **Version A (Control):** Blue Button.
* **Version B (Treatment):** Red Button.

You collect data from 1,000 users.

## The Frequentist Approach (The Problem)

In a traditional Frequentist framework (e.g., a t-test or Chi-square), you calculate a **p-value**.

If $p < 0.05$, you reject the null hypothesis. However, this approach has significant limitations for decision-making:
1.  **Indirect Meaning:** The p-value tells you the probability of seeing this data *assuming there is no difference*. It does *not* tell you the probability that Version B is better.
2.  **Point Estimates:** It often provides a single point estimate (e.g., "Conversion increased by 2%"), hiding the uncertainty distribution.
3.  **Peeking:** You are strictly forbidden from checking results early (stopping rules), which is impractical in business.

## The Bayesian Approach (The Solution)

Bayesian statistics answers the question you actually care about:
**"What is the probability that Version B is better than Version A?"**

We model the conversion rate of each version not as a fixed number, but as a **distribution of possibilities**. By comparing these two distributions, we can calculate direct probabilities of improvement/loss.

### Interactive Analysis

The simulation below models two conversion rates using Beta distributions.
* **Problem:** We observe raw data (trials and conversions).
* **Solution:** We visualize the uncertainty and calculate the "Probability of Improvement."

```{shinylive-python}
#| standalone: true
#| viewerHeight: 500

from shiny import App, render, ui
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import beta

app_ui = ui.page_fillable(
    ui.layout_columns(
        ui.card(
            ui.card_header("Experiment Data"),
            ui.h5("Version A (Control)"),
            ui.input_slider("trials_a", "Visitors A", 10, 1000, 500),
            ui.input_slider("conv_a", "Conversions A", 1, 200, 50),
            ui.hr(),
            ui.h5("Version B (Treatment)"),
            ui.input_slider("trials_b", "Visitors B", 10, 1000, 500),
            ui.input_slider("conv_b", "Conversions B", 1, 200, 60),
            
            ui.output_text_verbatim("prob_statement")
        ),
        ui.card(
            ui.card_header("Posterior Distributions"),
            ui.output_plot("ab_plot"),
        ),
        col_widths=[4, 8]
    )
)

def server(input, output, session):
    
    @render.text
    def prob_statement():
        # Monte Carlo Simulation to calculate Prob(B > A)
        # This is often easier/faster than numerical integration for A/B tests
        
        a_samples = beta.rvs(1 + input.conv_a(), 1 + (input.trials_a() - input.conv_a()), size=10000)
        b_samples = beta.rvs(1 + input.conv_b(), 1 + (input.trials_b() - input.conv_b()), size=10000)
        
        prob_b_better = np.mean(b_samples > a_samples)
        
        return (f"Based on this data:\n"
                f"There is a {prob_b_better:.1%} probability\n"
                f"that Version B is better than Version A.")

    @render.plot
    def ab_plot():
        # Define x-axis range around the observed means to zoom in
        mean_a = input.conv_a() / input.trials_a()
        mean_b = input.conv_b() / input.trials_b()
        avg_mean = (mean_a + mean_b) / 2
        
        x = np.linspace(max(0, avg_mean - 0.1), min(1, avg_mean + 0.1), 300)
        
        # Beta parameters (Flat prior alpha=1, beta=1 assumed)
        y_a = beta.pdf(x, 1 + input.conv_a(), 1 + (input.trials_a() - input.conv_a()))
        y_b = beta.pdf(x, 1 + input.conv_b(), 1 + (input.trials_b() - input.conv_b()))
        
        fig, ax = plt.subplots()
        
        # Plot A
        ax.plot(x, y_a, label='Version A', color='blue', lw=2)
        ax.fill_between(x, 0, y_a, color='blue', alpha=0.1)
        
        # Plot B
        ax.plot(x, y_b, label='Version B', color='red', lw=2)
        ax.fill_between(x, 0, y_b, color='red', alpha=0.1)
        
        ax.set_title("Uncertainty of Conversion Rates")
        ax.set_xlabel("True Conversion Rate")
        ax.set_yticks([]) # Hide y-axis as density magnitude is less intuitive
        ax.legend()
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_visible(False)
        
        return fig

app = App(app_ui, server)