# The Logic of Uncertainty

We begin with a concrete scenario common in medical diagnostics to understand why human intuition often fails at probability and how Bayesian reasoning provides the correct framework.

## The Scenario: A Rare Disease

Imagine a disease that affects **1%** of the population (the prevalence).
There is a test for this disease that is **99%** accurate. Specifically:
1.  **Sensitivity:** If you have the disease, the test is positive 99% of the time.
2.  **Specificity:** If you do *not* have the disease, the test is negative 99% of the time.

**The Problem:**
A patient takes the test and receives a **Positive** result. Intuitively, most people (and even many doctors) assume the probability the patient has the disease is near 99%.

**The Reality:**
The actual probability is only **50%**.

## The Failure of Intuition

Why is the intuitive answer wrong? It ignores the **Prior** (the prevalence). Because the disease is rare, the absolute number of *False Positives* from the massive healthy population overwhelms the *True Positives* from the tiny sick population.

Bayesian thinking forces us to account for this base rate.

## The Bayesian Solution

We do not look at the test accuracy in isolation. We update our prior belief based on the evidence.

$$P(\text{Disease} | \text{Positive}) = \frac{P(\text{Positive} | \text{Disease}) \cdot P(\text{Disease})}{P(\text{Positive})}$$

### Interactive Simulation

Use the dashboard below to visualize this relationship.
1.  Set the **Prevalence** to a low number (e.g., 0.01).
2.  Keep **Sensitivity** and **Specificity** high (0.99).
3.  Observe the bar chart. Note how the "False Positives" (Red) compete with the "True Positives" (Green).

```{shinylive-python}
#| standalone: true
#| viewerHeight: 550

from shiny import App, render, ui
import matplotlib.pyplot as plt
import numpy as np

app_ui = ui.page_fillable(
    ui.layout_columns(
        ui.card(
            ui.card_header("Diagnostic Parameters"),
            ui.input_slider("prevalence", "Prevalence (Prior Belief)", 0.001, 0.1, 0.01, step=0.001),
            ui.input_slider("sensitivity", "Sensitivity (True Positive Rate)", 0.9, 1.0, 0.99, step=0.001),
            ui.input_slider("specificity", "Specificity (True Negative Rate)", 0.9, 1.0, 0.99, step=0.001),
            ui.hr(),
            ui.output_text_verbatim("result_text")
        ),
        ui.card(
            ui.card_header("Population Breakdown"),
            ui.output_plot("bayes_plot"),
        ),
        col_widths=[4, 8]
    )
)

def server(input, output, session):
    
    @render.text
    def result_text():
        # calculations
        prev = input.prevalence()
        sens = input.sensitivity()
        spec = input.specificity()
        
        # Bayes Theorem
        p_pos_given_disease = sens
        p_pos_given_healthy = 1 - spec
        
        numerator = p_pos_given_disease * prev
        denominator = numerator + (p_pos_given_healthy * (1 - prev))
        
        post_prob = numerator / denominator
        
        return f"Probability of Disease given Positive Test:\n{post_prob:.1%}"

    @render.plot
    def bayes_plot():
        prev = input.prevalence()
        sens = input.sensitivity()
        spec = input.specificity()
        
        # Hypothetical population of 10,000
        n_pop = 10000
        n_sick = n_pop * prev
        n_healthy = n_pop * (1 - prev)
        
        # Outcomes
        true_pos = n_sick * sens
        false_neg = n_sick * (1 - sens)
        
        true_neg = n_healthy * spec
        false_pos = n_healthy * (1 - spec)
        
        # Plotting
        fig, ax = plt.subplots()
        
        # Data for stacked bars
        categories = ['Sick Population', 'Healthy Population']
        
        # Bar 1: Sick (Split into Detected and Missed)
        ax.bar(0, true_pos, color='#27ae60', label='True Positive (Correct)', width=0.6)
        ax.bar(0, false_neg, bottom=true_pos, color='#2c3e50', label='False Negative (Missed)', width=0.6, alpha=0.3)
        
        # Bar 2: Healthy (Split into True Negative and False Alarm)
        ax.bar(1, false_pos, color='#c0392b', label='False Positive (Alarm)', width=0.6)
        ax.bar(1, true_neg, bottom=false_pos, color='#95a5a6', label='True Negative (Correct)', width=0.6, alpha=0.3)
        
        ax.set_xticks([0, 1])
        ax.set_xticklabels(categories)
        ax.set_ylabel("Number of People")
        ax.set_title(f"Visualizing the Base Rate Fallacy (N={n_pop})")
        
        # Annotation to highlight the comparison
        ax.annotate(f"{int(true_pos)} True Pos", xy=(0, true_pos/2), ha='center', color='white', fontweight='bold')
        if false_pos > 5:
            ax.annotate(f"{int(false_pos)} False Pos", xy=(1, false_pos/2), ha='center', color='white', fontweight='bold')
        
        ax.legend()
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        
        return fig

app = App(app_ui, server)